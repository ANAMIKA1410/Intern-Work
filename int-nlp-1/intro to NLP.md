
   ![image](https://user-images.githubusercontent.com/84801896/123930173-1cc25700-d9ad-11eb-8077-a259212257a9.png)

  
  
   
  
  <b><center> This mark file down demonstrates that background work of NLP</b> </center>
  

### üìãINTRODUCTION To NLP

### 1.What is Natural Language processing ‚ùì

<p> Natural language processing (NLP) is a branch of artificial intelligence that helps computers understand, interpret and manipulate human language. NLP draws from many disciplines, including computer science and computational linguistics, in its pursuit to fill the gap between human communication and computer understanding.
<p> NLP combines computational linguistics‚Äîrule-based modeling of human language‚Äîwith statistical, machine learning, and deep learning models. Together, these technologies enable computers to process human language in the form of text or voice data and to ‚Äòunderstand‚Äô its full meaning, complete with the speaker or writer‚Äôs intent and sentiment. 
<p> NLP drives computer programs that translate text from one language to another, respond to spoken commands, and summarize large volumes of text rapidly‚Äîeven in real time. There‚Äôs a good chance you‚Äôve interacted with NLP in the form of voice-operated GPS systems, digital assistants, speech-to-text dictation software, customer service chatbots, and other consumer conveniences. But NLP also plays a growing role in enterprise solutions that help streamline business operations, 
  increase employee productivity, and simplify mission-critical business processes.
  
![image](![image](https://user-images.githubusercontent.com/84801896/123931189-036dda80-d9ae-11eb-8133-0b965f99a7c2.png)


  
  
  
 ### 2.Where we can use the natural language processing ‚ùì
  <p> Natural language processing (NLP) describes the interaction between human language and computers. It‚Äôs a technology that many people use daily and has been around for years, but is often taken for granted.

A few examples of NLP that people use every day are:

Spell check,
Autocomplete,
Voice text messaging,
Spam filters,
Related keywords on search engines,
Siri, Alexa, or Google Assistant.
    
<p> In any case, the computer is able to identify the appropriate word, phrase, or response by using context clues, the same way that any human would. Conceptually, it‚Äôs a fairly straightforward technology.

<p> Where NLP outperforms humans is in the amount of language and data it‚Äôs able to process. Therefore, its potential uses go beyond the examples above and make possible tasks that would‚Äôve otherwise taken employees months or years to accomplish.
  

  ### 3. History and Background work of NLP ‚ùì
  
  ![image](https://user-images.githubusercontent.com/84801896/123931617-4cbe2a00-d9ae-11eb-99f1-1a7229158465.png)

<p> While natural language processing isn‚Äôt a new science, the technology is rapidly advancing thanks to an increased interest in human-to-machine communications, plus an availability of big data, powerful computing and enhanced algorithms. 

<p> As a human, you may speak and write in English, Spanish or Chinese. But a computer‚Äôs native language ‚Äì known as machine code or machine language ‚Äì is largely incomprehensible to most people. At your device‚Äôs lowest levels, communication occurs not with words but through millions of zeros and ones that produce logical actions. 

<p> Indeed, programmers used punch cards to communicate with the first computers 70 years ago. This manual and arduous process was understood by a relatively small number of people. Now you can say, ‚ÄúAlexa, I like this song,‚Äù and a device playing music in your home will lower the volume and reply, ‚ÄúOK. Rating saved,‚Äù in a humanlike voice. Then it adapts its algorithm to play that song ‚Äì and others like it ‚Äì the next time you listen to that music station. 

<p> Let‚Äôs take a closer look at that interaction. Your device activated when it heard you speak, understood the unspoken intent in the comment, executed an action and provided feedback in a well-formed English sentence, all in the space of about five seconds. The complete interaction was made possible by NLP, along with other AI elements such as machine learning and deep learning. 

  ### Why is NLP important ‚ùî
 ### Large volumes of textual data
<p> Natural language processing helps computers communicate with humans in their own language and scales other language-related tasks. For example, NLP makes it possible for computers to read text, hear speech, interpret it, measure sentiment and determine which parts are important. 
Today‚Äôs machines can analyze more language-based data than humans, without fatigue and in a consistent, unbiased way. Considering the staggering amount of unstructured data that‚Äôs generated every day, from medical records to social media, automation will be critical to fully analyze text and speech data efficiently.

### Structuring a highly unstructured data source
<p> Human language is astoundingly complex and diverse. We express ourselves in infinite ways, both verbally and in writing. Not only are there hundreds of languages and dialects, but within each language is a unique set of grammar and syntax rules, terms and slang. When we write, we often misspell or abbreviate words, or omit punctuation. When we speak, we have regional accents, and we mumble, stutter and borrow terms from other languages. 
While supervised and unsupervised learning, and specifically deep learning, are now widely used for modeling human language, there‚Äôs also a need for syntactic and semantic understanding and domain expertise that are not necessarily present in these machine learning approaches. NLP is important because it helps resolve ambiguity in language and adds useful numeric structure to the data for many downstream applications, such as speech recognition or text analytics. 


  
 ### NLP methods and applications
  
  #### How computers make sense of textual data

  NLP and text analytics

<p> Natural language processing goes hand in hand with text analytics, which counts, groups and categorizes words to extract structure and meaning from large volumes of content. Text analytics is used to explore textual content and derive new variables from raw text that may be visualized, filtered, or used as inputs to predictive models or other statistical methods.

 <p> NLP and text analytics are used together for many applications, including:
     Investigative discovery. Identify patterns and clues in emails or written reports to help detect and solve crimes.
     Subject-matter expertise. Classify content into meaningful topics so you can take action and discover trends.
     Social media analytics. Track awareness and sentiment about specific topics and identify key influencers. 
  
  #### Everyday NLP examples 

<p>There are many common and practical applications of NLP in our everyday lives. Beyond conversing with virtual assistants like Alexa or Siri, here are a few more examples: 
<p>Have you ever looked at the emails in your spam folder and noticed similarities in the subject lines? You‚Äôre seeing Bayesian spam filtering, a statistical NLP technique that compares the words in spam to valid emails to identify junk mail.
<p>Have you ever missed a phone call and read the automatic transcript of the voicemail in your email inbox or smartphone app? That‚Äôs speech-to-text conversion, an NLP capability.
<p>Have you ever navigated a website by using its built-in search bar, or by selecting suggested topic, entity or category tags? Then you‚Äôve used NLP methods for search,
  topic modeling, entity extraction and content categorization.
  
  
 #### How does NLP work?
Breaking down the elemental pieces of language
  
<p> Natural language processing includes many different techniques for interpreting human language, ranging from statistical and machine learning methods to rules-based and algorithmic approaches. We need a broad array of approaches because the text- and voice-based data varies widely, as do the practical applications. 

<p>Basic NLP tasks include tokenization and parsing, lemmatization/stemming, part-of-speech tagging, language detection and identification of semantic relationships. If you ever diagramed sentences in grade school, you‚Äôve done these tasks manually before. In general terms, NLP tasks break down language into shorter, elemental pieces, try to understand relationships between the pieces and explore how the pieces work together to create meaning.

<p>These underlying tasks are often used in higher-level NLP capabilities, such as:

   #### Content categorization. 
 <p> A linguistic-based document summary, including search and indexing, content alerts and duplication detection.

   #### Topic discovery and modeling.
 <p>  Accurately capture the meaning and themes in text collections, and apply advanced analytics to text, like optimization and forecasting.

   #### Contextual extraction. 
 <p> Automatically pull structured information from text-based sources.

   #### Sentiment analysis. 
  <p> Identifying the mood or subjective opinions within large amounts of text, including average sentiment and opinion mining. 

   #### Speech-to-text and text-to-speech conversion. 
  <p> Transforming voice commands into written text, and vice versa. 

   #### Document summarization.
 <p> Automatically generating synopses of large bodies of text.

   #### Machine translation. 
 <p> Automatic translation of text or speech from one language to another.

In all these cases, the overarching goal is to take raw language input and use linguistics and algorithms to transform or enrich the text in such a way that it delivers greatervalue
   

   
   
   ### üìã 8 Natural Language Processing (NLP) Examples
   
 * Email filters
<p> Email filters are one of the most basic and initial applications of NLP online. It started out with spam filters, uncovering certain words or phrases that signal a spam message. But filtering has upgraded, just like early adaptations of NLP.
One of the more prevalent, newer applications of NLP is found in Gmail's email classification. The system recognizes if emails belong in one of three categories (primary, social, or promotions) based on their contents. For all Gmail users, this keeps your inbox to a manageable size with important, relevant emails you wish to review and respond to quickly.

 * Smart assistants
<p> Smart assistants like Apple‚Äôs Siri and Amazon‚Äôs Alexa recognize patterns in speech thanks to voice recognition, then infer meaning and provide a useful response. We‚Äôve become used to the fact that we can say ‚ÄúHey Siri,‚Äù ask a question, and she understands what we said and responds with relevant answers based on context. And we‚Äôre getting used to seeing Siri or Alexa pop up throughout our home and daily life as we have conversations with them through items like the thermostat, light switches, car, and more.
We now expect assistants like Alexa and Siri to understand contextual clues as they improve our lives and make certain activities easier like ordering items, and even appreciate when they respond humorously or answer questions about themselves. Our interactions will grow more personal as these assistants get to know more about us. As a New York Times article ‚ÄúWhy We May Soon Be Living in Alexa‚Äôs World,‚Äù explained: ‚ÄúSomething bigger is afoot. Alexa has the best shot of becoming the third great consumer computing platform of this decade.‚Äù

* Search results
<p> Search engines use NLP to surface relevant results based on similar search behaviors or user intent so the average person finds what they need without being a search-term wizard.
For example, Google not only predicts what popular searches may apply to your query as you start typing, but it looks at the whole picture and recognizes what you‚Äôre trying to say rather than the exact search words. Someone could put a flight number in Google and get the flight status, type a ticker symbol and receive stock information, or a calculator might come up when inputting a math equation. These are some variations you may see when completing a search as NLP in search associates the ambiguous query to a relative entity and provides useful results.

* Predictive text
<p> Things like autocorrect, autocomplete, and predictive text are so commonplace on our smartphones that we take them for granted. Autocomplete and predictive text are similar to search engines in that they predict things to say based on what you type, finishing the word or suggesting a relevant one. And autocorrect will sometimes even change words so that the overall message makes more sense.
They also learn from you. Predictive text will customize itself to your personal language quirks the longer you use it. This makes for fun experiments where individuals will share entire sentences made up entirely of predictive text on their phones. The results are surprisingly personal and enlightening; they‚Äôve even been highlighted by several media outlets.

* Language translation
<p> One of the tell-tale signs of cheating on your Spanish homework is that grammatically, it‚Äôs a mess. Many languages don‚Äôt allow for straight translation and have different orders for sentence structure, which translation services used to overlook. But, they‚Äôve come a long way.
With NLP, online translators can translate languages more accurately and present grammatically-correct results. This is infinitely helpful when trying to communicate with someone in another language. Not only that, but when translating from another language to your own, tools now recognize the language based on inputted text and translate it.

* Digital phone calls
<p> We all hear ‚Äúthis call may be recorded for training purposes,‚Äù but rarely do we wonder what that entails. Turns out, these recordings may be used for training purposes, if a customer is aggrieved, but most of the time, they go into the database for an NLP system to learn from and improve in the future. Automated systems direct customer calls to a service representative or online chatbots, which respond to customer requests with helpful information. This is a NLP practice that many companies, including large telecommunications providers have put to use.
NLP also enables computer-generated language close to the voice of a human. Phone calls to schedule appointments like an oil change or haircut can be automated, as evidenced by this video showing Google Assistant making a hair appointment.

* Data analysis
<p> Natural language capabilities are being integrated into data analysis workflows as more BI vendors offer a natural language interface to data visualizations. One example is smarter visual encodings, offering up the best visualization for the right task based on the semantics of the data. This opens up more opportunities for people to explore their data using natural language statements or question fragments made up of several keywords that can be interpreted and assigned a meaning.
Applying language to investigate data not only enhances the level of accessibility, but lowers the barrier to analytics across organizations, beyond the expected community of analysts and software developers.
To learn more about how natural language can help you better visualize and explore your data, check out this webinar.

* Text analytics
<p> Text analytics converts unstructured text data into meaningful data for analysis using different linguistic, statistical, and machine learning techniques.
While sentiment analysis sounds daunting to brands--especially if they have a large customer base--a tool using NLP will typically scour customer interactions, such as social media comments or reviews, or even brand name mentions to see what‚Äôs being said. Analysis of these interactions can help brands determine how well a marketing campaign is doing or monitor trending customer issues before they decide how to respond or enhance service for a better customer experience.
Additional ways that NLP helps with text analytics are keyword extraction and finding structure or patterns in unstructured text data.
There are vast applications of NLP in the digital world and this list will grow as businesses and industries embrace and see its value. While a human touch is important for more intricate communications issues, NLP will improve our lives by managing and automating smaller tasks first and then complex ones with technology innovation.
   
  . 

### Libraries in NLP

Natural Language Processing(NLP), a field of AI, aims to understand the semantics and connotations of natural human languages. It focuses on extracting meaningful information from text and train data models based on the acquired insights. The primary NLP functions include text mining, text classification, text analysis, sentiment analysis, word sequencing, speech recognition & generation, machine translation, and dialog systems, to name a few. 
Thanks to the development of useful NLP libraries, today, NLP is finding applications across the various parallels of the industrial landscape. In fact, NLP has now become an integral part of Deep Learning development. Extracting valuable information from free text is essential for developing chatbots, patent research & analysis, voice/speech recognition, patient data processing, and querying image content, among other use cases of NLP.
The fundamental aim of NLP libraries is to simplify text preprocessing. A good NLP library should be able to correctly convert free text sentences into structured features (for example, cost per hour) that can easily be fed into ML or DL pipelines. Also, an NLP library should have a simple-to-learn API, and it must be able to implement the latest and greatest algorithms and models efficiently. 
Although there are numerous NLP libraries designed for specific NLP applications, today, we‚Äôre going to draw a comparison of the functions of the top NLP libraries in Python. 


Now, let‚Äôs dive into the discussion about the top NLP libraries!



1. Natural Language Toolkit (NLTK)
2. Gensim
3. CoreNLP
4. spaCy
5. TextBlob



### 1.Natural Language Toolkit (NLTK)
NLTK is one of the leading platforms for building Python programs that can work with human language data. 
It presents a practical introduction to programming for language processing. NLTK comes with a host of text processing libraries for 
sentence detection, tokenization, lemmatization, stemming, parsing, chunking, and POS tagging. 


NLTK provides easy-to-use interfaces to over 50 corpora and lexical resources. 
The tool has the essential functionalities required for almost all kinds of natural language processing tasks with Python.

### Installation
 * pip install nltk
 ![nltk installation](https://github.com/ManishaAnaparthi/Images/blob/460075d94db4c4249ee61ae325c5ff22ca3d8b5e/Screenshot%20(3).png)
 

### Features


*   Stemming
*   Recommendation
*   Sentiment analysis
*   Translation


### 2.Gensim
Gensim is a Python library designed specifically for ‚Äútopic modeling, document indexing, and similarity retrieval with large corpora.‚Äù
All algorithms in Gensim are memory-independent, w.r.t., the corpus size, and hence, it can process input larger than RAM. With intuitive interfaces, Gensim allows for efficient multicore implementations of popular algorithms, including online Latent Semantic Analysis (LSA/LSI/SVD), Latent Dirichlet Allocation (LDA), Random Projections (RP), Hierarchical Dirichlet Process (HDP) or word2vec deep learning. 


Gensim features extensive documentation and Jupyter Notebook tutorials. It largely depends on NumPy and SciPy for scientific computing. 
Thus, you must install these two Python packages before installing Gensim.

  * Gensim is an open-source vector space and topic modelling toolkit.
  * Gensim uses numpy and sciPy.
  * Gensim is designed for data stemming ,habdle large text collections and efficient incremental algorithms.
  
 ### Installation
  
  * pip install gensim
  ![genism installation](https://github.com/ManishaAnaparthi/Images/blob/460075d94db4c4249ee61ae325c5ff22ca3d8b5e/Screenshot%20(4).png)
 

 
 ### Features
  
  * FastText
  * Word2Vec
  * Latent Semantic Analysis 
  * Latent dirichlet Allocation
  * tf-idf ( Term frequency-inverse document frequency)



### 3. CoreNLP
Stanford CoreNLP comprises of an assortment of human language technology tools. It aims to make the application of linguistic analysis tools to a piece of text easy and efficient. With CoreNLP, you can extract all kinds of text properties (like named-entity recognition, part-of-speech tagging, etc.) in only a few lines of code. 

Since CoreNLP is written in Java, it demands that Java be installed on your device. However, 
it does offer programming interfaces for many popular programming languages, including Python. 
The tool incorporates numerous Stanford‚Äôs NLP tools like the parser, sentiment analysis, bootstrapped pattern learning, part-of-speech (POS) tagger, 
named entity recognizer (NER), and coreference resolution system, to name a few. Furthermore, CoreNLP supports four languages apart from 
English ‚Äì Arabic, Chinese, German, French, and Spanish.

### Installation
  * pip install stanford-corenlp
 ![corenlp  installation](https://github.com/ManishaAnaparthi/Images/blob/460075d94db4c4249ee61ae325c5ff22ca3d8b5e/Screenshot%20(5).png)
 
### Features
  * Lemmatization
  * Part-Of-Speech Tagging
  * Morphological Tagging
  * Named ENtity Recognition
  * Tokenization
  * Sentence Splitting

  

### 4.spaCy

spaCy is an open-source NLP library in Python. It is designed explicitly for production usage ‚Äì it lets you develop applications that process and understand huge volumes of text.  

spaCy can preprocess text for Deep Learning. It can be be used to build natural language understanding systems or information extraction systems. 
spaCy is equipped with pre-trained statistical models and word vectors. It can support tokenization for over 49 languages. 
spaCy boasts of state-of-the-art speed, parsing, named entity recognition, convolutional neural network models for tagging, and deep learning integration.


### Installation
  * pip install -U spacy
  * ![spacy installation](https://raw.githubusercontent.com/ManishaAnaparthi/Images/main/Screenshot%20(2).png)

### Features
  * Tokenization
  * POS Tagging 
  * Dependency Parsing
  * Lemmatization
  * Sentence Boundary Detection
  * Named Entity Recognition
  * Entity Linking
  * Text Classification
  * Similarity
  


### 5.TextBlob

TextBlob is a Python (2 & 3) library designed for processing textual data. It focuses on providing access to common text-processing operations through familiar interfaces. TextBlob objects can be treated as Python strings that are trained in Natural Language Processing.

TextBlob offers a neat API for performing common NLP tasks like part-of-speech tagging, noun phrase extraction, sentiment analysis, classification, language translation, 
word inflection, parsing, n-grams, and WordNet integration.
### Installation
 
   * pip install -U tectblob
   * python _m textblob.download_corpora
  
### Features
   * Tokenization
   * Parsing
   * Spelling Corrrection
   * Sentiment Analysis
   * Part-Of_Speech tagging
   * n-grams
   * Translation
   * word & phrase frequencies
   

### 6.Pattern

Pattern is a text processing, web mining, natural language processing, machine learning, and network analysis tool for Python. It comes with a host of tools for data mining (Google, Twitter, Wikipedia API, a web crawler, and an HTML DOM parser), NLP (part-of-speech taggers, n-gram search, sentiment analysis, WordNet), 
ML (vector space model, clustering, SVM), and network analysis by graph centrality and visualization. 
### Installation
 
   * pip install pattern
   * ![patern installation](https://raw.githubusercontent.com/ManishaAnaparthi/Images/main/Screenshot%20(1).png)
  

# Introduction to Numpy

### What is Numpy ?
* NumPy is the fundamental package for scientific computing in Python. It is a Python library that provides a multidimensional array object, 
various derived objects (such as masked arrays and matrices), and an assortment of routines for fast operations on arrays, including mathematical, logical, shape manipulation, 
sorting, selecting, I/O, discrete Fourier transforms, basic linear algebra, basic statistical operations, random simulation and much more.

* Our Python NumPy Tutorial provides the basic and advanced concepts of the NumPy. Our NumPy tutorial is designed for beginners and professionals.
NumPy stands for numeric python which is a python package for the computation and processing of the multidimensional and single dimensional array elements.

* Travis Oliphant created NumPy package in 2005 by injecting the features of the ancestor module Numeric into another module Numarray.
It is an extension module of Python which is mostly written in C. It provides various functions which are capable of performing the numeric computations with a high speed.
NumPy provides various powerful data structures, implementing multi-dimensional arrays and matrices. These data structures are used for the optimal computations regarding
arrays and matrices.

### The need of NumPy
With the revolution of data science, data analysis libraries like NumPy, SciPy, Pandas, etc. have seen a lot of growth. With a much easier syntax than other programming languages, python is the first choice language for the data scientist.
NumPy provides a convenient and efficient way to handle the vast amount of data. NumPy is also very convenient with Matrix multiplication and data reshaping. NumPy is fast which makes it reasonable to work with a large set of data.

There are the following advantages of using NumPy for data analysis.

* NumPy performs array-oriented computing.
* It efficiently implements the multidimensional arrays.
* It performs scientific computations.
* It is capable of performing Fourier Transform and reshaping the data stored in multidimensional arrays.
* NumPy provides the in-built functions for linear algebra and random number generation.
* Nowadays, NumPy in combination with SciPy and Mat-plotlib is used as the replacement to MATLAB as Python is more complete and easier programming language than MATLAB.

### NumPy Environment Setup
NumPy doesn't come bundled with Python. We have to install it using the python pip installer. Execute the following command.
```
pip install numpy 

```

### Creating Arrays in Numpy 

```
import numpy as np
arr = np.array([1,2,3,4,5,6,7,8,9,10])

```

### Array Dimensions

1. 0-D Arrays

```
arr = np.array(42)
```

2. 1-D Arrays

 ```
 arr = np.array([1,2,3,4,5,6,7,8,9,10])
 ```
 
 3. 2-D Arrays
 
 ```
 arr = np.array([[1,2,3,4],[5,6,7,8]])
 ```
 
 4. 3-D Arrays
 ```
 arr = np.array([[[1,2,3],[4,5,6]],[[7,8,9],[10,11,12]]])
 ```
 
 ### Numpy Array Slicing :
 
 * Slicing in python means taking elements from one given index to another given index.
 * We pass slice instead of index like `[start:end]`
 * We can also define the step like `[start:end:step]`
 * If we don't pass start, start is considered 0
 * If we don't pass end , it is considered as last element of the dimension
 * If we don't pass step, it is considered to be 1
 
 ```
arr = np.array([1, 2, 3, 4, 5, 6, 7])
arr[1:5]
arr[4,:]
arr[:,4]
arr[-3:-1]
arr[::2]
arr[1,2:5]
arr[0:2,1:3]
 ``` 
 ### Data Types in Numpy

* i - Integer
* b - Boolean
* u - Unsigned Integer
* f - Float
* c - Complex Float
* m - Timedelta
* M - Datetime
* O - Object
* S - String 
* U - Unicode String
* V - Fixed chunk of memory for other type

### Shape of an array

* The shape of an array is the number of elements in each dimension.
* It can be determined using `arr.shape`
* Integers at every index tells about the number of elements the corresponding dimension has.


### Joining Numpy Arrays

* Joining means putting contents of two or more arrays in a single array.
* In SQL we join tables based on a key, whereas in NumPy we join arrays by axes.
* We pass a sequence of arrays that we want to join to the `concatenate()` function, along with the axis. If axis is not explicitly passed, it is taken as 0.

**Example 1**
```
arr1 = np.array([1, 2, 3])

arr2 = np.array([4, 5, 6])

arr = np.concatenate((arr1, arr2))

```

**Example 2**
```
arr1 = np.array([[1, 2], [3, 4]])

arr2 = np.array([[5, 6], [7, 8]])

arr = np.concatenate((arr1, arr2), axis=1)
 
 ```

**Example 3**
```
numpy.concatenate() with axis=0
import numpy as np  
x=np.array([[1,2],[3,4]])  
y=np.array([[12,30]])
z=np.concatenate((x,y), axis=0)  
z
```
 **Example 4**
 ```
numpy.concatenate() with axis=1
import numpy as np  
x=np.array([[1,2],[3,4]])  
y=np.array([[12,30]])  
z=np.concatenate((x,y.T), axis=1)  
z  
```


### numpy.append() in Python
The numpy.append() function is available in NumPy package. As the name suggests, append means adding something.
The numpy.append() function is used to add or append new values to an existing numpy array. This function adds the new values at the end of the array.
The numpy append() function is used to merge two arrays. It returns a new array, and the original array remains unchanged.

# Syntax
* numpy.append(arr, values, axis=None)  

 **Example 1**
```
np.append()
import numpy as np  
a=np.array([[10, 20, 30], [40, 50, 60], [70, 80, 90]])  
b=np.array([[11, 21, 31], [42, 52, 62], [73, 83, 93]])  
c=np.append(a,b)  
c
```

**Example 2**
```
#np.append({a1,a2,...}, axis=0)
import numpy as np  
a=np.array([[10, 20, 30], [40, 50, 60], [70, 80, 90]])  
b=np.array([[11, 21, 31], [42, 52, 62], [73, 83, 93]])  
c=np.append(a,b,axis=0)  
c 
```

**Example 3**
```
np.append({a1,a2,...}, axis=1)
import numpy as np  
a=np.array([[10, 20, 30], [40, 50, 60], [70, 80, 90]])  
b=np.array([[11, 21, 31], [42, 52, 62], [73, 83, 93]])  
c=np.append(a,b,axis=1)  
c
```

### numpy.sum() in Python
The numpy.sum() function is available in the NumPy package of Python. This function is used to compute the sum of all elements, the sum of each row, and the sum of each column of a given array.
Essentially, this sum ups the elements of an array, takes the elements within a ndarray, and adds them together. It is also possible to add rows and column elements of an array.
The output will be in the form of an array object

![image](https://user-images.githubusercontent.com/84801896/123977559-b6edc380-d9dc-11eb-8b72-cf25468012b4.png)
### Syntax
There is the following syntax of numpy.sum() function:
numpy.sum(arr, axis=None, dtype=None, out=None, keepdims=<no value>, initial=<no value>) 
  
  
**Example 1**
 ```
numpy.array()
import numpy as np  
a=np.array([0.4,0.5])  
b=np.sum(a)  
b  
```
**Example 2**
 ```
import numpy as np  
a=np.array([0.4,0.5,0.9,6.1])  
x=np.sum(a, dtype=np.int32)  
x 
  
 ```
  
### numpy.zeros() in Python
The numpy.zeros() function is one of the most significant functions which is used in machine learning programs widely. This function is used to generate an array containing zeros.
The numpy.zeros() function provide a new array of given shape and type, which is filled with zeros.
  ![image](https://user-images.githubusercontent.com/84801896/123979062-041e6500-d9de-11eb-860a-86ba6ebb55bc.png)
  ### Syntax
* numpy.zeros(shape, dtype=float, order='C'  
  
  **Example 1**
   ```
  numpy.zeros() without dtype and order
  import numpy as np  
  a=np.zeros(6)  
  a  
   ```
  **Example 2**
  
   ```
  numpy.zeros() with shape
  import numpy as np  
  a=np.zeros((6,2))  
  a  
  
   ```
 
  **Example 3**
  ```
  numpy.zeros() with the shape
  Import numpy as np  
  s1=(3,2)  
  a=np.zeros(s1)  
  a  
   ```
  
